{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font face=\"Verdana\" size=6 color='#6495ED'>  THIS IS ME\n",
        "\n",
        "<font face=\"Verdana\" size=3 color='#40E0D0'> Profs. Larissa Driemeier, Thiago Martins\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?export=view&id=1LYiTAE2KG5dJf_qIoVKOluUhzrK-AmfP' width=\"600\"></center>\n",
        "\n",
        "Na próximas duas aulas, vocês irão construir um programa para reconhecimento facial de qualquer colega seu do curso de IA. Para isso, serão 3 etapas:\n",
        "1. Geração de Eigenfaces - utilização do banco de dados *Labeled Faces in the Wild* (LFW) em conjunto com as fotos de seus colegas, para extrair as características principais de uma face humana via PCA;\n",
        "2. Criação um classificador SVM para reconhecimento facial de seus colegas;\n",
        "3. Utilização do classificador em tempo real na competição em sala.\n",
        "\n",
        "Prontos? Este é o __TERCEIRO__ Notebook! Estamos quase lá... Hora da competição\n",
        "\n",
        "A Webcam captura fotos de colegas e permite que você teste seu algoritmo. Aqui você receberá bastante ajuda, mas terá que automatizar todo o reconhecimento:\n",
        "- foto é tirada pela webcam;\n",
        "- foto é cortada, redimensionada, e PCA é aplicado;\n",
        "- entra no classificador;\n",
        "- o computador cumprimenta seu colega: __\"Olá, Fulano de Tal!\"__\n"
      ],
      "metadata": {
        "id": "TM8qyxjRo4G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import html\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "import os"
      ],
      "metadata": {
        "id": "rr-u7an3pchW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font face=\"Verdana\" size=6 color='#6495ED'>   Captura de imagem\n",
        "\n",
        "O código abaixo, em Javascript, foi adaptado do Google Colab Snippets e é utilizado para capturar uma foto da câmera."
      ],
      "metadata": {
        "id": "vPCZQmMwnfem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tirar_foto(quality=0.8, texto_botao=\"Capturar\"):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(qual, texto) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = texto;\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      // Abre a câmera\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "      // Mostra a saída da câmera\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', qual);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  return eval_js('takePhoto({}, \"{}\")'.format(quality, texto_botao))"
      ],
      "metadata": {
        "id": "8wtrmRwXnkEd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A linha de código abaixo utiliza o Haar Cascade, que é um dos mais antigos e poderosos algoritmos de detecção de rosto em tempo real inventados (muito antes do Deep Learning se tornar famoso), e podemos acessá-los com métodos OpenCV. Haar Features não foram usados apenas para detectar rostos, mas também para olhos, lábios, etc. O algoritmo usa recursos de detecção de borda ou linha propostos por Viola e Jones em seu trabalho de pesquisa [Rapid Object Detection using a Boosted Cascade of Simple Features](https://ieeexplore.ieee.org/document/990517) publicado em 2001. Ambas as técnicas ainda serão aprendidas no seu curso de IA."
      ],
      "metadata": {
        "id": "ZnFunMhSnpYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "haar_face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "metadata": {
        "id": "BZEPARVDnzuW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função abaixo corte imagens muito grandes..."
      ],
      "metadata": {
        "id": "9l9P7ZvXnorE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_square(img, size, interpolation=cv2.INTER_AREA):\n",
        "    h, w = img.shape[:2]\n",
        "    min_size = np.amin([h,w])\n",
        "\n",
        "    # Centralize and crop\n",
        "    crop_img = img[int(h/2-min_size/2):int(h/2+min_size/2), int(w/2-min_size/2):int(w/2+min_size/2)]\n",
        "    resized = cv2.resize(crop_img, (size, size), interpolation=interpolation)\n",
        "\n",
        "    return resized"
      ],
      "metadata": {
        "id": "DALoMh56pXtj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  imagem_urlb64 = tirar_foto()\n",
        "  imbytes = b64decode(imagem_urlb64.split(',')[1])\n",
        "  im = cv2.imdecode(np.frombuffer(imbytes, dtype=np.uint8), flags=1)\n",
        "  plt.imshow(im, cmap='gray'),plt.title('Imagem capturada')\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "OrOpYNvZn2-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)"
      ],
      "metadata": {
        "id": "iAeLTAs-omyR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é apenas uma observação. Caso você queira fazer upload de uma imagem, os passoa o seguinte código deve substituir a captura de imagem:\n",
        "\n",
        "* Upload da imagem:\n",
        "```\n",
        "uploaded = files.upload()\n",
        "```\n",
        "\n",
        "* Para cada rosto detectado, tem-se quatro características `x, y, largura,altura`, isto é, coordenadas `x,y` do canto inferior esquerdo do rosto e `largura, altura` do retângulo que define o rosto. Portanto, a matriz `rostos` definida acima deve ter dimensão `número de rostos detectados` $\\times$ 4.\n",
        "```\n",
        "name = 'IMG_20220112_173025.jpg'\n",
        "im = cv2.imread(name)\n",
        "plt.imshow(im, cmap='gray'),plt.title('Imagem capturada')\n",
        "#diminuindo a dimensão da imagem\n",
        "im = crop_square(im, 250)\n",
        "# Imagem em escala de cinzas\n",
        "gray = cv2.cvtColor(im,cv2.COLOR_RGB2GRAY)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HGauN6hyn-Xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font face=\"Verdana\" size=6 color='#6495ED'>  Reconhecimento da posição da face\n",
        "Agora usaremos o Haar Cascade para reconhecimento da imagem."
      ],
      "metadata": {
        "id": "z6NIAN-dpJZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconhecimento de faces\n",
        "rostos = haar_face_cascade.detectMultiScale(im)\n",
        "\n",
        "print(f'{rostos.shape[0]} rosto(s) detectado(s)')\n",
        "n_rostos = rostos.shape[0]\n",
        "\n",
        "print(f'\\n A matriz rostos:\\n {rostos}')"
      ],
      "metadata": {
        "id": "Hjp9YEttpILQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colocando o retângulo ao redor da face reconhecida\n",
        "for (x, y, largura, altura) in rostos:\n",
        "  im_r = cv2.rectangle(im,(x,y),(x+largura,y+altura),(255,0,0),2)\n",
        "#Plotando a imagem\n",
        "plt.imshow(im_r, cmap='gray'),plt.title('Rosto(s) Detectado(s)')"
      ],
      "metadata": {
        "id": "UYIIctUqpuQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zoom no rosto detectado\n",
        "\n",
        "plt.figure(figsize=(12,12)) # specifying the overall grid size\n",
        "i=0\n",
        "for (x, y, largura, altura) in rostos:\n",
        "  i += 1\n",
        "  plt.subplot(1,n_rostos,i)    # the number of images in the grid is 5*5 (25)\n",
        "  plt.imshow(cv2.cvtColor(im[y:y+altura, x:x+largura], cv2.COLOR_BGR2RGB))\n",
        "  plt.title('image '+ str(i)+'largura: '+str(largura)+'x altura:'+str(altura))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPQltEA1p2gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se houver vários rostos, escolha o quadro desenhado ao redor da maior imagem,\n",
        "x, y, largura, altura = rostos[rostos[:,-1].argsort()[-1]] #\n",
        "print(x,y,largura,altura)\n",
        "plt.imshow(gray[y:y+altura, x:x+largura], cmap='gray'),plt.title('Rosto Escolhido')"
      ],
      "metadata": {
        "id": "242InvySp5V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'A imagem mostrada acima tem {largura} pixels de largura e {altura} pixels de altura \\nEssa imagem que deverá ser reconhecida!!!')"
      ],
      "metadata": {
        "id": "gQ1XaIY3qA9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se essa é a imagem que deve ser reconhecida, então precisamos transformá-la para nosso tamanho padrão, ié, `altura_lfw = 125` e  `largura_lfw = 94`"
      ],
      "metadata": {
        "id": "dv77zCt0qWA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# relação altura vs largura das imagens do do banco de dados LFW\n",
        "altura_lfw = 62\n",
        "largura_lfw = 47\n",
        "razao_aspecto = altura_lfw/largura_lfw\n",
        "print(f'As imagens tem uma relação altura vs largura de {razao_aspecto}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UdJf6eZqiVl",
        "outputId": "fbce4cab-153a-469e-b55d-488b25d70a30"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As imagens tem uma relação altura vs largura de 1.3191489361702127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_rate(img, x,y,largura,altura, largura_lfw = 94, altura_lfw = 125, interpolation=cv2.INTER_AREA): #cv2.INTER_AREA\n",
        "      razao_aspecto = altura_lfw/largura_lfw\n",
        "      centro_x = x + largura/2\n",
        "      centro_y = y + altura/2\n",
        "      area = largura*altura\n",
        "      largura_adj = np.sqrt(area/razao_aspecto)\n",
        "      altura_adj = razao_aspecto*largura_adj\n",
        "      x_min = int(np.floor(centro_x-largura_adj/2))\n",
        "      x_max = int(np.ceil(centro_x+largura_adj/2))\n",
        "      y_min = int(np.floor(centro_y-altura_adj/2 + 0.5))\n",
        "      y_max = int(np.ceil(centro_y+altura_adj/2 + 0.5))\n",
        "      if y_min <0:\n",
        "         y_max -= y_min\n",
        "         y_min = 0\n",
        "      if x_min <0:\n",
        "         x_max -= x_min\n",
        "         x_min = 0\n",
        "      # Centralize and crop\n",
        "      crop_img = img[y_min:y_max, x_min:x_max]\n",
        "      img_lfw = cv2.resize(crop_img, (largura_lfw, altura_lfw), interpolation=interpolation)\n",
        "\n",
        "      print(img_lfw.shape)\n",
        "      return img_lfw"
      ],
      "metadata": {
        "id": "Uvst7FIiqvOt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pessoa = crop_rate(gray,x=x,y=y,largura=largura,altura=altura)\n",
        "plt.imshow(Pessoa, cmap='gray'),plt.title('Imagem para ser reconhecida')"
      ],
      "metadata": {
        "id": "mINuBuC1q3Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font face=\"Verdana\" size=6 color='#6495ED'> Modelo"
      ],
      "metadata": {
        "id": "UBijosMtmEbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Não esqueça de carregar seu poderoso classificador e o PCA."
      ],
      "metadata": {
        "id": "RVK1tUi3pWPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9fKnq47Ymd0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "import pickle as pk"
      ],
      "metadata": {
        "id": "JLSI0HOypnVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "TPtPYPTnpx5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = pk.load(open('gdrive/MyDrive/AprendizadoMaquinasI/2022/ThisIsMe/PCA/pca.pkl', 'rb'))\n",
        "model = pk.load(open('gdrive/MyDrive/AprendizadoMaquinasI/2022/ThisIsMe/SVM/model_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "J_6T0hNsphvT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}